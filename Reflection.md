**1.Project Overview**
For the project, I selected two books from Project Gutenberg: “An Inquiry…” by Adam Smith, and “The Federalist Papers” by Alexander Hamilton. This project is created to better understand text mining and different techniques used in text analysis. I intended to analyze both texts by counting the total number of words (excluding stop words); the top 10 most frequently used words in both texts and their differences, the sentiment analysis score for each text (including visualization) and their differences; as well as the Jaccard Similarity coefficient to look at how similar both texts are. 

**2. Implementation**
At a system level, there are a 4 general sections to this project, including a process-file section, a summary analysis section, a sentiment analysis section, and a text similarity index analysis section. Throughout the entire project, I utilized mostly lists and dictionaries as data structure to support my analysis as they are both fit for computing summary statistics.
For the process-file section: I found both books from Project Gutenberg and downloaded the utf-8 txt files to my local folder. I downloaded the files directly to my folder, instead of using python function because it is “easier” and more straightforward in downloading the texts because there are only two of them. As opposed to processing files directly from Project Gutenberg or downloading via python functions, it takes more time to access files online and for analyzing larger numbers of files, it makes more sense to access directly to online locations, instead of downloading them, which is why I did not write a function to download. This is adapted from my own assumptions and from discussions with Prof. Li during office hours Mar 24th. Note, when processing files, the headers and ending of Project Gutenberg are already removed using process_file function and all stop words in stopwords.txt file are also removed. Also, all punctuations and white spaces are removed from the books and all words are converted to a dictionary with the words as keys and the frequency they appear as values.
For the summary analysis section: I chose to compute the total number of words and the top 10 words with the highest frequencies in appearing in both books. This is the compare the lengths of the books and try to find out the main topic of the books using the most frequently appeared words.
For the sentiment analysis section: sentiment analysis scores were computed for both books to investigate its tones, whether they are more negative, positive, or neutral. To compare the sentiment analysis scores from both books, I wrote a function that subtracts the two scores and compute their differences. Both sets of sentiment analysis scores for Smith and Hamilton are then plotted on a bar chart for better visualization.
For the text similarity section: there was a decision made between using Jaccard Similarity coefficient and Cosine Similarity. After researching their differences, I decided to go with Jaccard coefficient as it ignores duplications of words. Jaccard similarity takes “a unique set of words” from each document and tries to analyze how “similar” in words are the two documents. On the other hand, cosine similarity takes “total length of the vectors” which are converted from vectors (https://towardsdatascience.com/overview-of-text-similarity-metrics-3397c4601f50). Since in my analysis, duplications does not matter to me, and while selecting the books, I knew from prior knowledge that Smith and Hamilton are addressing different topics, I chose to use Jaccard Similarity method. The research and code adaptions are from: https://towardsdatascience.com/overview-of-text-similarity-metrics-3397c4601f50.

**3. Results** 
the total numbers of words from Smith’s book are 170373, while the total numbers of words from Hamilton’s book are 84004. This shows that Smith's book is tremendously longer than Hamilton's book, which is expected as it addressed a larger, more philosophical topic. 
The top 10 most frequently occurred words from Smith’s book are: {'great': 1582, 'part': 1398, 'price': 1264, 'country': 1240, 'greater': 1085, 'labour': 1011, 'trade': 970, 'produce': 943, 'quantity': 797, 'value': 792}
This correlates with the general topic of taxation and national strength, which is shown through words like labour, trade, value, and etc.
The top 10 most frequently occurred words from Hamilton’s book are: {'states': 854, 'government': 833, 'state': 788, 'power': 619, 'people': 613, 'constitution': 466, 'union': 376, 'new': 370, 'national': 342, 'federal': 325}
This correlates with Hamilton's topic of the US and his view, which is shown by words like states, government, people, constitution, and etc.
The differences between the top 10 most frequently occurred words are: ['great', 'part', 'price', 'country', 'greater', 'labour', 'trade', 'produce', 'quantity', 'value', 'states', 'government', 'state', 'power', 'people', 'constitution', 'union', 'new', 'national', 'federal']
There is a large difference in word use between the two texts, none of them overlapps in fact, which is understandable as both texts address different topics.
The sentiment analysis score for Smith’s book is: {'neg': 0.054, 'neu': 0.806, 'pos': 0.14, 'compound': 1.0}
This shows that Smith's book is mostly neutral (from Smith.png), which is expected from a "philosophical" text.
The sentiment analysis score for Hamilton’s score is: {'neg': 0.073, 'neu': 0.795, 'pos': 0.132, 'compound': 1.0}
This shows that Hamilton's text is mostly neutral (from Hamilton.png) which is expected as he was trying to convey a message for both sides of the argument to understand.
The differences in sentiment analysis score is: {'neg': 0.018999999999999996, 'neu': -0.01100000000000001, 'pos': -0.008000000000000007, 'compound': 0.0}
The differences in score reflects that both texts are similar that they are both neutral, but Hamilton's text has a slightly more negative tone than Smith's text.
The Jaccard Similarity Coefficient is: 0.27453
The Jaccard Similarity Coefficient of 0.27453 shows that the texts are largely different, which is again, expected when selecting the texts in the first place and correlates with prior findings from total words and top 10 most frequent words.

**4. Reflection**
I think what went well was the class material analyze_book.py and how understanding that laid a good foundation in completing this project. Additionally, I think this open-ended project is really interesting and allowed room for me to explore. For instance, both books I selected, especially the one from Adam Smith, comes from my other class: Tax Policy. I think for me, getting started early was definitely a plus. Although the majority of the code for me was finished before the weekend, I took some extra time before the due date and explored a bit more around the required content, which was fun. I think my topic was appropriately scoped and I was able to create good content from the project. I wish I could have asked a bit more during office hours about the other techniques in text analysis such as thefuzz, or text clustering, if applicable to my project. Nonetheless, I explored myself and found a index that should be interesting and correlates to my project. This project intimately connects to my term project which is about mininig data from Capital IQ and generating DCF analysis. I think by fully understanding the underlying logic behind this assignment, it will tremendously help my term project.